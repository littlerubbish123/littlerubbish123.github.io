<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="二分类问题(x,y ) 表示某一个样本，y的取值是0|1  ,$X^n$表示n维的特征向量,训练集有m个样本$$(X^i，Y^i),…(X^m,Y^m)$$输入特征向量的维度（x1,x2,…,xm) ，所以是n * m 的矩阵 ，Y表示每个样本的预测结果$$X &#x3D;  [X^1,X^2,…,X^m]$$$$Y &#x3D; [Y^1,Y^2,…,Y^n]$$ logistic回归给定x的取值，求y&#x3D;1的条件概">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/2022/11/10/network/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="二分类问题(x,y ) 表示某一个样本，y的取值是0|1  ,$X^n$表示n维的特征向量,训练集有m个样本$$(X^i，Y^i),…(X^m,Y^m)$$输入特征向量的维度（x1,x2,…,xm) ，所以是n * m 的矩阵 ，Y表示每个样本的预测结果$$X &#x3D;  [X^1,X^2,…,X^m]$$$$Y &#x3D; [Y^1,Y^2,…,Y^n]$$ logistic回归给定x的取值，求y&#x3D;1的条件概">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="c:/Users/123/AppData/Roaming/Typora/typora-user-images/image-20221109161303373.png">
<meta property="og:image" content="https://images.gitbook.cn/31a064f0-811d-11e8-9614-476580d74a06">
<meta property="article:published_time" content="2022-11-10T02:29:44.582Z">
<meta property="article:modified_time" content="2022-11-10T13:06:36.750Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="c:/Users/123/AppData/Roaming/Typora/typora-user-images/image-20221109161303373.png">

<link rel="canonical" href="http://example.com/2022/11/10/network/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title> | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/11/10/network/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2022-11-10 10:29:44 / Modified: 21:06:36" itemprop="dateCreated datePublished" datetime="2022-11-10T10:29:44+08:00">2022-11-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="二分类问题"><a href="#二分类问题" class="headerlink" title="二分类问题"></a><strong>二分类问题</strong></h2><p>(x,y ) 表示某一个样本，y的取值是0|1  ,$X^n$表示n维的特征向量,训练集有m个样本<br>$$<br>(X^i，Y^i),…(X^m,Y^m)<br>$$<br>输入特征向量的维度（x1,x2,…,xm) ，所以是n * m 的矩阵 ，Y表示每个样本的预测结果<br>$$<br>X =  [X^1,X^2,…,X^m]<br>$$<br>$$<br>Y = [Y^1,Y^2,…,Y^n]<br>$$</p>
<h2 id="logistic回归"><a href="#logistic回归" class="headerlink" title="logistic回归"></a><strong>logistic回归</strong></h2><p>给定x的取值，求y=1的条件概率 ，参数w是一个n维向量，b是常量，假设w和b已知</p>
<p>$$<br>y = f(w^T + b)<br>$$<br>这里f 是sigmoid函数，将取值映射（0,1）<br>$$<br>sigmod=\frac{1}{1+e^{-z}}<br>$$</p>
<p>cost funtion 寻找最合适的w和b</p>
<p>一般的loss function shi是误差平方和，但在logistic回归（分类）中，我们使用的是<br>$$<br>-(y *lg\hat{ y} + (1-y)*log(1-\hat{y}))<br>$$<br>损失函数和是全体样本的cost function J(W,b)，minJ是我们的求解目标</p>
<img src="C:\Users\123\AppData\Roaming\Typora\typora-user-images\image-20221109161303373.png" alt="image-20221109161303373" style="zoom:67%;" >

<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a><strong>梯度下降</strong></h3><p>梯度下降法为了最小化cost function，找到合适的w和b，logistic的cost function是凸函数，存在全局最小值，</p>
<p>沿着梯度方向下降</p>
<p>$$<br>repeat: w =  w - \alpha  \frac{dJ(w,b)}{dw}   b =  b - \alpha  \frac{dJ(w,b)}{db}<br>$$</p>
<ul>
<li><h5 id="单个样本的损失函数求导"><a href="#单个样本的损失函数求导" class="headerlink" title="单个样本的损失函数求导"></a>单个样本的损失函数求导</h5></li>
</ul>
<p>$$<br>z = W^TX+b<br>$$</p>
<p>$$<br>a= sigmoid(z)<br>$$</p>
<p>$$<br>L(a,y)=-y(log(a)+(1-y)log(1-a))<br>$$</p>
<p>求损失函数L对于w的偏导数(打不出偏导数的符号) ,先求对z的偏导数<br>$$<br>\frac{\partial L(a,y)}{\partial z} = \frac{\partial L}{ \partial a} * \frac{\partial a}{\partial z}<br>$$</p>
<p>$$<br>=(-\frac{y}{a}+\frac{1-y}{1-a} ) * (a-a^2) = a-y<br>$$</p>
<p>如果我们的单个样本是2维的话，即z = w1<em>x1+w2</em>x2+b ，那么dL/dw1 = x1 * (a - y) </p>
<p>在一次更新里面，对于单个样本进行更新 w1= w1- a* (dL/dw1),w2 = w2-a*(dL/dw2),</p>
<p>d= d-a*(dL/dd)</p>
<ul>
<li><h5 id="推广到多个样本的测试集上"><a href="#推广到多个样本的测试集上" class="headerlink" title="推广到多个样本的测试集上"></a>推广到多个样本的测试集上</h5></li>
</ul>
<p>$$<br>\frac{\partial J}{ \partial w_1} = \frac{1}{m} \sum_{i=1}^{m}\frac{\partial L(a^{(i)},y^{(i)})}{\partial w_1}<br>$$</p>
<p>这里的算法就是对m个样本对于w1的 偏导数之和 除以m（不同样本的损失函数 ，对于w1求偏导，再相加 ，然后除以m个样本，可以认为是成本函数在w1上的偏导数）</p>
<p>完成一次所有参数的更新上，多次梯度下降，直到J到达某个阈值</p>
<h3 id="向量化技术"><a href="#向量化技术" class="headerlink" title="向量化技术"></a>向量化技术</h3><p>减少显式的for循环  。。。。</p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p><img src="https://images.gitbook.cn/31a064f0-811d-11e8-9614-476580d74a06" alt="img"></p>
<p>可以看到在隐藏层他们经历了logistic的同样的过程，z=$W^T$X+b，然后通过sigmoid函数，结果作为隐藏层是输入和最后一层的输入。</p>
<p>现在使用向量化技术就是矩阵乘法，将权重值表示为矩阵的形式。<br>$$<br>\left[\begin{matrix}W_{11}{ }W_{12}W_{13}\W_{21}W_{22} W_{23}\W_{31} W_{32} W_{33} \W_{41} W_{42}W_{43} \end{matrix}\right] * \left[<br> \begin{matrix}<br>      X_1 \X_2 \X_3<br>  \end{matrix}<br>  \right]+\vec{b}=Z^{[1]}<br>$$</p>
<p>$$<br>sigmoid(Z^{[1]}) = a^{[2]}<br>$$</p>
<p>图中的$X_1$,$X_2$,$X_3$ 是看做一个样本的特征矩阵，如何以矩阵乘法的方式实现神经网络的输入呢。<br>$$<br>\vec{X} = [\vec{X^{(1)}},\vec{X^{(2)}},…,\vec{X^{(m)}}]<br>$$<br>输入的矩阵是一个n<em>m的矩阵，如果隐藏层是一个k * n 的矩阵，$W^T$X+b得到的隐藏层的输出矩阵，是k</em>m的</p>
<p>可以认为之前的n维特征变成k维的了。</p>
<h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>sigmoid函数（二分类的输出层） ；</p>
<p>tanh函数（应用于隐藏层）（better） ；</p>
<p>（ 这两个函数在自变量很大的时候变化率很小，会导致梯度下降变慢；）</p>
<p>修正线性单元 （ReLU)，也是如果不知道隐藏层用什么的选择。</p>
<p>leaky ReLU</p>
<p>为什么必须使用非线性函数作为激活函数？</p>
<p>这么做其实只是将输入的特征值经过线性组合再次输出。</p>
<h4 id="神经网络的的梯度下降法"><a href="#神经网络的的梯度下降法" class="headerlink" title="神经网络的的梯度下降法"></a>神经网络的的梯度下降法</h4><p>复习一下正向传播的公式<br>$$<br>第一层 Z^{[1]} =W^{[1]}X + b^{[1]}<br>$$</p>
<p>$$<br>第一层的输出 A^{[1]} = g^{[1]} (Z^{[1]})<br>$$</p>
<p>$$<br>第二层  Z^{[2]} =W^{[2]}A^{[1]} + b^{[2]}<br>$$</p>
<p>$$<br>第二层的输出 A^{[2]} = g^{[2]} (Z^{[2]})<br>$$</p>
<p>这里以sigmoid 函数为例，介绍一下反向传播的公式的计算</p>
<p>这里是第一次，整个网络中的W和b都是初始化的，我们</p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item"></div>
      <div class="post-nav-item">
    <a href="/2022/11/10/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/" rel="next" title="">
       <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="nav-number">1.</span> <span class="nav-text">二分类问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#logistic%E5%9B%9E%E5%BD%92"><span class="nav-number">2.</span> <span class="nav-text">logistic回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.1.</span> <span class="nav-text">梯度下降</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8D%95%E4%B8%AA%E6%A0%B7%E6%9C%AC%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%B1%82%E5%AF%BC"><span class="nav-number">2.1.0.1.</span> <span class="nav-text">单个样本的损失函数求导</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8E%A8%E5%B9%BF%E5%88%B0%E5%A4%9A%E4%B8%AA%E6%A0%B7%E6%9C%AC%E7%9A%84%E6%B5%8B%E8%AF%95%E9%9B%86%E4%B8%8A"><span class="nav-number">2.1.0.2.</span> <span class="nav-text">推广到多个样本的测试集上</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%8C%96%E6%8A%80%E6%9C%AF"><span class="nav-number">2.2.</span> <span class="nav-text">向量化技术</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">3.</span> <span class="nav-text">神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-number">3.0.1.</span> <span class="nav-text">激活函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E7%9A%84%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="nav-number">3.0.2.</span> <span class="nav-text">神经网络的的梯度下降法</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
